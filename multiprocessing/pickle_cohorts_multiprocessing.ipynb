{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost on Network Model Cohorts\n",
    "Including Simplified Menu Type as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import multiprocessing\n",
    "import queue\n",
    "\n",
    "import data_functions as dataf\n",
    "import postgres_functions as pg\n",
    "import plot_functions as plotter\n",
    "from clustering_query import snowflake_query\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_smt(df):\n",
    "    '''Gets customer info to add dummy columns for smplfd_menu_desc.\n",
    "\n",
    "    :param df: dataframe with cust_nbr and div_nbr\n",
    "    :type df: pd.DataFrame\n",
    "    '''\n",
    "    # pull cust_info to add smplfd_menu_desc, then dummy it\n",
    "    cust_info = dataf.get_cust_info()\n",
    "    df = pd.merge(df, cust_info.loc[:, ['cust_nbr', 'div_nbr',\n",
    "                                        'smplfd_menu_desc']],\n",
    "                  on=['cust_nbr', 'div_nbr'],\n",
    "                  how='inner')\n",
    "\n",
    "    df = pd.get_dummies(df,\n",
    "                        prefix='',\n",
    "                        prefix_sep='',\n",
    "                        columns=['smplfd_menu_desc'],\n",
    "                        dummy_na=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Threshold and pkl name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pkl_name = 'ind_liu'\n",
    "table_name = 'cohorts_first_pass'\n",
    "pyr_seg = 'IND'\n",
    "f1_threshold = 0.1\n",
    "min_cohort_size = 75\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Get data from postgres table ```cohorts_first_pass```. Then query Snowflake for PIM Group Description to merge to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohorts = pg.get_first_pass_table(table_name)\n",
    "cohorts = pd.read_csv(f'../data/{table_name}_{pyr_seg}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6912116 entries, 0 to 6912115\n",
      "Data columns (total 10 columns):\n",
      "cust_nbr                  int64\n",
      "div_nbr                   int64\n",
      "pim_grp_id_actl           int64\n",
      "case_volume               int64\n",
      "cust_grp_pct_of_basket    float64\n",
      "source                    object\n",
      "target                    object\n",
      "source_cohort             object\n",
      "target_cohort             object\n",
      "last_update               object\n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 527.4+ MB\n"
     ]
    }
   ],
   "source": [
    "cohorts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dataframe to only max date\n",
    "cohorts = cohorts[cohorts['last_update'] == cohorts['last_update'].max()]\n",
    "cohorts['pim_grp_id_actl'] = cohorts['pim_grp_id_actl'].astype(str)\n",
    "cohorts['cust_nbr'] = cohorts['cust_nbr'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved product data less than 1 week old.\n",
      "Importing product data from prod_desc.csv...\n"
     ]
    }
   ],
   "source": [
    "prod_info = dataf.get_product_info()\n",
    "cohorts = pd.merge(cohorts, prod_info, on='pim_grp_id_actl', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_nbr</th>\n",
       "      <th>div_nbr</th>\n",
       "      <th>pim_grp_id_actl</th>\n",
       "      <th>case_volume</th>\n",
       "      <th>cust_grp_pct_of_basket</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_cohort</th>\n",
       "      <th>target_cohort</th>\n",
       "      <th>last_update</th>\n",
       "      <th>pim_group_description</th>\n",
       "      <th>usf_category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000560</td>\n",
       "      <td>2110</td>\n",
       "      <td>1370</td>\n",
       "      <td>45</td>\n",
       "      <td>0.036378</td>\n",
       "      <td>s100005602110</td>\n",
       "      <td>t1370</td>\n",
       "      <td>ind_cohort_0</td>\n",
       "      <td>ind_cohort_20</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>APPETIZERS, ONIONS, BREADED &amp; BATTERED</td>\n",
       "      <td>APPETIZERS AND COATED VEGETABLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000074</td>\n",
       "      <td>2230</td>\n",
       "      <td>1370</td>\n",
       "      <td>14</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>s10000742230</td>\n",
       "      <td>t1370</td>\n",
       "      <td>ind_cohort_2</td>\n",
       "      <td>ind_cohort_20</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>APPETIZERS, ONIONS, BREADED &amp; BATTERED</td>\n",
       "      <td>APPETIZERS AND COATED VEGETABLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000710</td>\n",
       "      <td>2270</td>\n",
       "      <td>1370</td>\n",
       "      <td>279</td>\n",
       "      <td>0.063538</td>\n",
       "      <td>s10007102270</td>\n",
       "      <td>t1370</td>\n",
       "      <td>ind_cohort_6</td>\n",
       "      <td>ind_cohort_20</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>APPETIZERS, ONIONS, BREADED &amp; BATTERED</td>\n",
       "      <td>APPETIZERS AND COATED VEGETABLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001338</td>\n",
       "      <td>2135</td>\n",
       "      <td>1370</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>s10013382135</td>\n",
       "      <td>t1370</td>\n",
       "      <td>ind_cohort_1</td>\n",
       "      <td>ind_cohort_20</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>APPETIZERS, ONIONS, BREADED &amp; BATTERED</td>\n",
       "      <td>APPETIZERS AND COATED VEGETABLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001726</td>\n",
       "      <td>2240</td>\n",
       "      <td>1370</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>s10017262240</td>\n",
       "      <td>t1370</td>\n",
       "      <td>ind_cohort_8</td>\n",
       "      <td>ind_cohort_20</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>APPETIZERS, ONIONS, BREADED &amp; BATTERED</td>\n",
       "      <td>APPETIZERS AND COATED VEGETABLES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_nbr  div_nbr pim_grp_id_actl  case_volume  cust_grp_pct_of_basket  \\\n",
       "0  10000560     2110            1370           45                0.036378   \n",
       "1   1000074     2230            1370           14                0.013527   \n",
       "2   1000710     2270            1370          279                0.063538   \n",
       "3   1001338     2135            1370            2                0.000394   \n",
       "4   1001726     2240            1370           27                0.002001   \n",
       "\n",
       "          source target source_cohort  target_cohort last_update  \\\n",
       "0  s100005602110  t1370  ind_cohort_0  ind_cohort_20  2019-05-20   \n",
       "1   s10000742230  t1370  ind_cohort_2  ind_cohort_20  2019-05-20   \n",
       "2   s10007102270  t1370  ind_cohort_6  ind_cohort_20  2019-05-20   \n",
       "3   s10013382135  t1370  ind_cohort_1  ind_cohort_20  2019-05-20   \n",
       "4   s10017262240  t1370  ind_cohort_8  ind_cohort_20  2019-05-20   \n",
       "\n",
       "                    pim_group_description          usf_category_description  \n",
       "0  APPETIZERS, ONIONS, BREADED & BATTERED  APPETIZERS AND COATED VEGETABLES  \n",
       "1  APPETIZERS, ONIONS, BREADED & BATTERED  APPETIZERS AND COATED VEGETABLES  \n",
       "2  APPETIZERS, ONIONS, BREADED & BATTERED  APPETIZERS AND COATED VEGETABLES  \n",
       "3  APPETIZERS, ONIONS, BREADED & BATTERED  APPETIZERS AND COATED VEGETABLES  \n",
       "4  APPETIZERS, ONIONS, BREADED & BATTERED  APPETIZERS AND COATED VEGETABLES  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohorts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation and Customer-Group Crosstab\n",
    "Create a dataframe that gives a crosstab with ```cust_nbr``` as index and ```pim_group_description``` as columns, and ```cust_grp_pct_of_basket``` as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Creating crosstab...\n"
     ]
    }
   ],
   "source": [
    "cust_grp = dataf.create_crosstab(cohorts, 'pim_group_description', 'cust_grp_pct_of_basket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Simplified Menu Type\n",
    "Get customer info, then dummy Simplified Menu Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved customer data less than 1 week old.\n",
      "Importing customer data from cust_data.csv...\n"
     ]
    }
   ],
   "source": [
    "cust_grp = add_smt(cust_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_nbr</th>\n",
       "      <th>div_nbr</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, BULK, REFRIGERATED</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, BULK, SHELF STABLE</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, SINGLE SERVICE, REFRIGERATED</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, SINGLE SERVICE, SHELF STABLE</th>\n",
       "      <th>ADMINISTRATIVE</th>\n",
       "      <th>AIR FRESHENER</th>\n",
       "      <th>ALL PURPOSE CLEANER / POLISH</th>\n",
       "      <th>ALLIGATOR, FROZEN</th>\n",
       "      <th>...</th>\n",
       "      <th>FROZEN DESSERTS</th>\n",
       "      <th>HAMBURGERS</th>\n",
       "      <th>LATIN AMERICAN</th>\n",
       "      <th>MEXICAN</th>\n",
       "      <th>OTHER ASIAN</th>\n",
       "      <th>OTHER ETHNIC FOOD</th>\n",
       "      <th>PIZZA, PASTA &amp; ITALIAN</th>\n",
       "      <th>SANDWICHES, SOUPS AND SALADS, DELI, SUBS &amp; HOT DOG</th>\n",
       "      <th>SMT UNAVAILABLE</th>\n",
       "      <th>STEAK, SEAFOOD &amp; FISH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000560</td>\n",
       "      <td>2110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000066</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000074</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000090</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001238</td>\n",
       "      <td>2110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_nbr  div_nbr  1000 ISLAND SALAD DRESSING, BULK, REFRIGERATED  \\\n",
       "0  10000560     2110                                             0.0   \n",
       "1   1000066     2230                                             0.0   \n",
       "2   1000074     2230                                             0.0   \n",
       "3   1000090     2230                                             0.0   \n",
       "4  10001238     2110                                             0.0   \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, BULK, SHELF STABLE  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, SINGLE SERVICE, REFRIGERATED  \\\n",
       "0                                                0.0          \n",
       "1                                                0.0          \n",
       "2                                                0.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, SINGLE SERVICE, SHELF STABLE  ADMINISTRATIVE  \\\n",
       "0                                                0.0                    0.0   \n",
       "1                                                0.0                    0.0   \n",
       "2                                                0.0                    0.0   \n",
       "3                                                0.0                    0.0   \n",
       "4                                                0.0                    0.0   \n",
       "\n",
       "   AIR FRESHENER  ALL PURPOSE CLEANER / POLISH  ALLIGATOR, FROZEN  ...  \\\n",
       "0            0.0                           0.0                0.0  ...   \n",
       "1            0.0                           0.0                0.0  ...   \n",
       "2            0.0                           0.0                0.0  ...   \n",
       "3            0.0                           0.0                0.0  ...   \n",
       "4            0.0                           0.0                0.0  ...   \n",
       "\n",
       "   FROZEN DESSERTS  HAMBURGERS  LATIN AMERICAN  MEXICAN  OTHER ASIAN  \\\n",
       "0                0           0               0        0            0   \n",
       "1                0           0               0        0            1   \n",
       "2                0           0               0        0            0   \n",
       "3                1           0               0        0            0   \n",
       "4                0           0               0        0            0   \n",
       "\n",
       "   OTHER ETHNIC FOOD  PIZZA, PASTA & ITALIAN  \\\n",
       "0                  0                       0   \n",
       "1                  0                       0   \n",
       "2                  0                       0   \n",
       "3                  0                       0   \n",
       "4                  0                       0   \n",
       "\n",
       "   SANDWICHES, SOUPS AND SALADS, DELI, SUBS & HOT DOG  SMT UNAVAILABLE  \\\n",
       "0                                                  0                 0   \n",
       "1                                                  0                 0   \n",
       "2                                                  0                 0   \n",
       "3                                                  0                 0   \n",
       "4                                                  0                 0   \n",
       "\n",
       "   STEAK, SEAFOOD & FISH  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 2220 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize columns to use as features of model\n",
    "model_cols = cust_grp.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1000 ISLAND SALAD DRESSING, BULK, REFRIGERATED',\n",
       "       '1000 ISLAND SALAD DRESSING, BULK, SHELF STABLE',\n",
       "       '1000 ISLAND SALAD DRESSING, SINGLE SERVICE, REFRIGERATED',\n",
       "       '1000 ISLAND SALAD DRESSING, SINGLE SERVICE, SHELF STABLE',\n",
       "       'ADMINISTRATIVE', 'AIR FRESHENER', 'ALL PURPOSE CLEANER / POLISH',\n",
       "       'ALLIGATOR, FROZEN', 'ALMONDS', 'AMMONIA & BLEACH',\n",
       "       ...\n",
       "       'FROZEN DESSERTS', 'HAMBURGERS', 'LATIN AMERICAN', 'MEXICAN',\n",
       "       'OTHER ASIAN', 'OTHER ETHNIC FOOD', 'PIZZA, PASTA & ITALIAN',\n",
       "       'SANDWICHES, SOUPS AND SALADS, DELI, SUBS & HOT DOG', 'SMT UNAVAILABLE',\n",
       "       'STEAK, SEAFOOD & FISH'],\n",
       "      dtype='object', length=2218)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write out features to use with pickled model\n",
    "# dataf.write_jsonl_file(model_cols, f'../data/model_features_{partial_pkl_name}.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_nbr</th>\n",
       "      <th>div_nbr</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, BULK, REFRIGERATED</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, BULK, SHELF STABLE</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, SINGLE SERVICE, REFRIGERATED</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, SINGLE SERVICE, SHELF STABLE</th>\n",
       "      <th>ADMINISTRATIVE</th>\n",
       "      <th>AIR FRESHENER</th>\n",
       "      <th>ALL PURPOSE CLEANER / POLISH</th>\n",
       "      <th>ALLIGATOR, FROZEN</th>\n",
       "      <th>...</th>\n",
       "      <th>FROZEN DESSERTS</th>\n",
       "      <th>HAMBURGERS</th>\n",
       "      <th>LATIN AMERICAN</th>\n",
       "      <th>MEXICAN</th>\n",
       "      <th>OTHER ASIAN</th>\n",
       "      <th>OTHER ETHNIC FOOD</th>\n",
       "      <th>PIZZA, PASTA &amp; ITALIAN</th>\n",
       "      <th>SANDWICHES, SOUPS AND SALADS, DELI, SUBS &amp; HOT DOG</th>\n",
       "      <th>SMT UNAVAILABLE</th>\n",
       "      <th>STEAK, SEAFOOD &amp; FISH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000560</td>\n",
       "      <td>2110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000066</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000074</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000090</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001238</td>\n",
       "      <td>2110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_nbr  div_nbr  1000 ISLAND SALAD DRESSING, BULK, REFRIGERATED  \\\n",
       "0  10000560     2110                                             0.0   \n",
       "1   1000066     2230                                             0.0   \n",
       "2   1000074     2230                                             0.0   \n",
       "3   1000090     2230                                             0.0   \n",
       "4  10001238     2110                                             0.0   \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, BULK, SHELF STABLE  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, SINGLE SERVICE, REFRIGERATED  \\\n",
       "0                                                0.0          \n",
       "1                                                0.0          \n",
       "2                                                0.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, SINGLE SERVICE, SHELF STABLE  ADMINISTRATIVE  \\\n",
       "0                                                0.0                    0.0   \n",
       "1                                                0.0                    0.0   \n",
       "2                                                0.0                    0.0   \n",
       "3                                                0.0                    0.0   \n",
       "4                                                0.0                    0.0   \n",
       "\n",
       "   AIR FRESHENER  ALL PURPOSE CLEANER / POLISH  ALLIGATOR, FROZEN  ...  \\\n",
       "0            0.0                           0.0                0.0  ...   \n",
       "1            0.0                           0.0                0.0  ...   \n",
       "2            0.0                           0.0                0.0  ...   \n",
       "3            0.0                           0.0                0.0  ...   \n",
       "4            0.0                           0.0                0.0  ...   \n",
       "\n",
       "   FROZEN DESSERTS  HAMBURGERS  LATIN AMERICAN  MEXICAN  OTHER ASIAN  \\\n",
       "0                0           0               0        0            0   \n",
       "1                0           0               0        0            1   \n",
       "2                0           0               0        0            0   \n",
       "3                1           0               0        0            0   \n",
       "4                0           0               0        0            0   \n",
       "\n",
       "   OTHER ETHNIC FOOD  PIZZA, PASTA & ITALIAN  \\\n",
       "0                  0                       0   \n",
       "1                  0                       0   \n",
       "2                  0                       0   \n",
       "3                  0                       0   \n",
       "4                  0                       0   \n",
       "\n",
       "   SANDWICHES, SOUPS AND SALADS, DELI, SUBS & HOT DOG  SMT UNAVAILABLE  \\\n",
       "0                                                  0                 0   \n",
       "1                                                  0                 0   \n",
       "2                                                  0                 0   \n",
       "3                                                  0                 0   \n",
       "4                                                  0                 0   \n",
       "\n",
       "   STEAK, SEAFOOD & FISH  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 2220 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_grp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Crosstab with Cohort Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_unique_df = cohorts.loc[:, ['cust_nbr', 'div_nbr', 'source_cohort']]\n",
    "cohort_unique_df = cohort_unique_df.drop_duplicates()\n",
    "\n",
    "# merge crosstab with cust_df\n",
    "cust_grp = pd.merge(cust_grp, cohort_unique_df, on = ['cust_nbr', 'div_nbr'], how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write File out for DataRobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not needed for input\n",
    "outfile = cust_grp.copy()\n",
    "outfile.drop('cust_nbr', axis=1, inplace=True)\n",
    "outfile.drop('div_nbr', axis=1, inplace=True)\n",
    "\n",
    "# write out file for datarobot\n",
    "outfile.to_csv(f'../data/dr_{partial_pkl_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Cohort Dummies and Initialize labelCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_nbr</th>\n",
       "      <th>div_nbr</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, BULK, REFRIGERATED</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, BULK, SHELF STABLE</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, SINGLE SERVICE, REFRIGERATED</th>\n",
       "      <th>1000 ISLAND SALAD DRESSING, SINGLE SERVICE, SHELF STABLE</th>\n",
       "      <th>ADMINISTRATIVE</th>\n",
       "      <th>AIR FRESHENER</th>\n",
       "      <th>ALL PURPOSE CLEANER / POLISH</th>\n",
       "      <th>ALLIGATOR, FROZEN</th>\n",
       "      <th>...</th>\n",
       "      <th>HAMBURGERS</th>\n",
       "      <th>LATIN AMERICAN</th>\n",
       "      <th>MEXICAN</th>\n",
       "      <th>OTHER ASIAN</th>\n",
       "      <th>OTHER ETHNIC FOOD</th>\n",
       "      <th>PIZZA, PASTA &amp; ITALIAN</th>\n",
       "      <th>SANDWICHES, SOUPS AND SALADS, DELI, SUBS &amp; HOT DOG</th>\n",
       "      <th>SMT UNAVAILABLE</th>\n",
       "      <th>STEAK, SEAFOOD &amp; FISH</th>\n",
       "      <th>source_cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000560</td>\n",
       "      <td>2110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ind_cohort_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000066</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ind_cohort_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000074</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ind_cohort_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000090</td>\n",
       "      <td>2230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ind_cohort_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001238</td>\n",
       "      <td>2110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ind_cohort_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_nbr  div_nbr  1000 ISLAND SALAD DRESSING, BULK, REFRIGERATED  \\\n",
       "0  10000560     2110                                             0.0   \n",
       "1   1000066     2230                                             0.0   \n",
       "2   1000074     2230                                             0.0   \n",
       "3   1000090     2230                                             0.0   \n",
       "4  10001238     2110                                             0.0   \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, BULK, SHELF STABLE  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, SINGLE SERVICE, REFRIGERATED  \\\n",
       "0                                                0.0          \n",
       "1                                                0.0          \n",
       "2                                                0.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   1000 ISLAND SALAD DRESSING, SINGLE SERVICE, SHELF STABLE  ADMINISTRATIVE  \\\n",
       "0                                                0.0                    0.0   \n",
       "1                                                0.0                    0.0   \n",
       "2                                                0.0                    0.0   \n",
       "3                                                0.0                    0.0   \n",
       "4                                                0.0                    0.0   \n",
       "\n",
       "   AIR FRESHENER  ALL PURPOSE CLEANER / POLISH  ALLIGATOR, FROZEN  ...  \\\n",
       "0            0.0                           0.0                0.0  ...   \n",
       "1            0.0                           0.0                0.0  ...   \n",
       "2            0.0                           0.0                0.0  ...   \n",
       "3            0.0                           0.0                0.0  ...   \n",
       "4            0.0                           0.0                0.0  ...   \n",
       "\n",
       "   HAMBURGERS  LATIN AMERICAN  MEXICAN  OTHER ASIAN  OTHER ETHNIC FOOD  \\\n",
       "0           0               0        0            0                  0   \n",
       "1           0               0        0            1                  0   \n",
       "2           0               0        0            0                  0   \n",
       "3           0               0        0            0                  0   \n",
       "4           0               0        0            0                  0   \n",
       "\n",
       "   PIZZA, PASTA & ITALIAN  SANDWICHES, SOUPS AND SALADS, DELI, SUBS & HOT DOG  \\\n",
       "0                       0                                                  0    \n",
       "1                       0                                                  0    \n",
       "2                       0                                                  0    \n",
       "3                       0                                                  0    \n",
       "4                       0                                                  0    \n",
       "\n",
       "   SMT UNAVAILABLE  STEAK, SEAFOOD & FISH  source_cohort  \n",
       "0                0                      0   ind_cohort_0  \n",
       "1                0                      0   ind_cohort_1  \n",
       "2                0                      0   ind_cohort_2  \n",
       "3                0                      0   ind_cohort_3  \n",
       "4                0                      0   ind_cohort_4  \n",
       "\n",
       "[5 rows x 2221 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for cohort columns\n",
    "cust_grp = pd.get_dummies(cust_grp, prefix='', prefix_sep='', columns=['source_cohort'], dummy_na=False)\n",
    "\n",
    "# initialize label_cols to iterate through models (ignore feat columns, cust_nbr, div_nbr).\n",
    "label_cols = cust_grp.columns[len(model_cols) + 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge additional customer info for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Submitting Snowflake query...\n",
      "-----------\n",
      "Retriving Datassentials customer info...\n",
      "------------------\n",
      "Submitting Snowflake query...\n"
     ]
    }
   ],
   "source": [
    "# get cust_corp info\n",
    "query = '''\n",
    "        SELECT cust_nbr, \n",
    "            div_nbr, \n",
    "            cust_nm, \n",
    "            smplfd_menu_desc\n",
    "        FROM cust_corp\n",
    "        '''\n",
    "cust_names = snowflake_query(query)\n",
    "\n",
    "# datassentials info\n",
    "datass = dataf.get_datassentials_custs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "cust_grp = pd.merge(cust_grp, cust_names, on = ['cust_nbr', 'div_nbr'], how = 'left')\n",
    "cust_grp = pd.merge(cust_grp, datass, on = ['cust_nbr', 'div_nbr'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost for Feature Importance\n",
    "We want to look at the feature importance that comes from a Gradient Boost model for each of the cohort labels. For each dummy column, we use a One-vs-Rest (OvR) schema to train the model for that cohort.\n",
    "\n",
    "At each iteration the classes are imbalanced, so we are using a stratified train-test split for cross-validation. Consider upsampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_liu_ind_cohort_1.pkl\n",
      "ind_liu_ind_cohort_0.pkl\n"
     ]
    }
   ],
   "source": [
    "# # remove previous pkl files\n",
    "# print('--------\\nRemoving old pkl files...')\n",
    "# for filename in os.listdir('pkl'):\n",
    "#     if partial_pkl_name in filename:\n",
    "#         print(filename)\n",
    "#         os.remove(f'pkl/{filename}')\n",
    "        \n",
    "# print('Time elapased, in minutesd: {:.2f}'.format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_pickle_model(df, X, y, label_col, pq):\n",
    "#     print(f'\\n+++++++++++++++++++++\\n Label: {label_col}')\n",
    "    y = df.loc[:, label_col]\n",
    "\n",
    "    print(f'Label Value Counts:\\n{y.value_counts()}')\n",
    "\n",
    "    # if there are fewer than 75 customers in a cohort generated by the network model, don't pickle\n",
    "    if y.sum() < min_cohort_size:\n",
    "        print('Cohort size below threshold.')\n",
    "\n",
    "    else:\n",
    "        # perform a stratified train-test split for imbalanced classes\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=123)\n",
    "\n",
    "        gb = GradientBoostingClassifier(loss='deviance', \n",
    "                                        learning_rate = 0.05, \n",
    "                                        n_estimators=2500, \n",
    "                                        criterion='friedman_mse', \n",
    "                                        min_samples_split=2, \n",
    "                                        min_samples_leaf=1, \n",
    "                                        max_depth=5, \n",
    "                                        random_state=123, \n",
    "                                        max_features=0.2, \n",
    "                                        max_leaf_nodes=None, \n",
    "                                        subsample=1.0,\n",
    "                                        verbose=0)\n",
    "\n",
    "        gb.fit(X_train, y_train)\n",
    "        y_pred = gb.predict(X_test)\n",
    "\n",
    "        # get scores\n",
    "        f1, recall, precision, accuracy = dataf.score_model(y_test, y_pred)\n",
    "        cohort_scores = {'cohort': label_col, \n",
    "                   'scores': {'f1': f1, \n",
    "                              'recall': recall, \n",
    "                              'precision': precision, \n",
    "                              'accuracy': accuracy}}\n",
    "        dataf.write_json_file(cohort_scores, '../data/model_scores_{partial_pkl_name}.jsonl')\n",
    "        print(f'{label_col}, f1: {f1}')\n",
    "\n",
    "        # Plot the feature importance\n",
    "        feat_scores = pd.Series(gb.feature_importances_, index=model_cols)\n",
    "\n",
    "        top_scores = feat_scores.sort_values()[::-1][:20][::-1]\n",
    "\n",
    "        # plot feature importances\n",
    "        ax = top_scores.plot(kind='barh', figsize=(10, 8), color='g')\n",
    "        ax.set_title(f'Feature Importance (Friedman MSE) for {label_col}')\n",
    "        ax.set_xlabel('Contribution to Information Gain')\n",
    "        plt.show()\n",
    "\n",
    "        # print out top 5 smplfd_menu_desc and cuisine_secondary\n",
    "        subdf = df[df[label_col] == 1]\n",
    "        for col in ['smplfd_menu_desc', 'cuisine_secondary']:\n",
    "            # create ordered dictionary of value_counts and get top\n",
    "            rankings = collections.OrderedDict(subdf[col].value_counts())\n",
    "            tops = itertools.islice(rankings.items(), 0, 5)\n",
    "            plotter.plot_dict(dict(tops), f'Top 5 {col} for {label_col}', figsize=(8, 4))\n",
    "\n",
    "        # print out top 25 cust_nm\n",
    "        rankings = collections.OrderedDict(subdf['cust_nm'].value_counts())\n",
    "        tops = itertools.islice(rankings.items(), 0, 25)\n",
    "        print(f'--------------\\nTop 25 cust_nm for {label_col}\\n--------------')\n",
    "        for key, value in tops:\n",
    "            print(f'{key}\\t{value}')\n",
    "\n",
    "        if f1 < f1_threshold:\n",
    "            print('F1 Score below threshold! Not pickling this model.\\n-------')\n",
    "            \n",
    "        else:\n",
    "            # append scores to lists\n",
    "#             f1_list.append(f1)\n",
    "#             recall_list.append(recall)\n",
    "#             precision_list.append(precision)\n",
    "#             accuracy_list.append(accuracy)\n",
    "            \n",
    "            pq.put(f1)\n",
    "#             proc_queue.put(recall)\n",
    "#             proc_queue.put(precision)\n",
    "#             proc_queue.put(accuracy)\n",
    "\n",
    "            # append top features to outfile\n",
    "#             outfile = outfile.append(dataf.feat_importance_df(top_scores, label_col))\n",
    "#             proc_queue.put(dataf.feat_importance_df(top_scores, label_col))\n",
    "            \n",
    "#             # pickle the model\n",
    "#             print(f'Pickling {label_col} model...')\n",
    "#             pickle_path = f'pkl/{partial_pkl_name}_{label_col}.pkl'\n",
    "#             joblib.dump(gb, pickle_path)\n",
    "#             model_list.append(pickle_path[4:-4])\n",
    "#             print('Pickling complete.')\n",
    "            \n",
    "    print('Time elapsed, in minutes: {:.2f}'.format((time.time() - start_time) / 60))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_cohort_0', 'ind_cohort_1', 'ind_cohort_10', 'ind_cohort_11']\n",
      "Label Value Counts:\n",
      "0    76969\n",
      "1     5598\n",
      "Name: ind_cohort_0, dtype: int64Label Value Counts:\n",
      "0    77566\n",
      "1     5001\n",
      "Name: ind_cohort_1, dtype: int64\n",
      "\n",
      "Label Value Counts:\n",
      "0    78375\n",
      "1     4192\n",
      "Name: ind_cohort_10, dtype: int64\n",
      "Label Value Counts:\n",
      "0    81889\n",
      "1      678\n",
      "Name: ind_cohort_11, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-89690406f750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mf1_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#         recall_list.append(proc_queue.get())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-67:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-79-e192e81d905d>\", line 28, in train_and_pickle_model\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1465, in fit\n",
      "    begin_at_stage, monitor, X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1529, in _fit_stages\n",
      "    X_csc, X_csr)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1194, in _fit_stage\n",
      "    check_input=False, X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 1142, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 366, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "KeyboardInterrupt\n",
      "Process Process-66:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-79-e192e81d905d>\", line 28, in train_and_pickle_model\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1465, in fit\n",
      "    begin_at_stage, monitor, X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1529, in _fit_stages\n",
      "    X_csc, X_csr)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1194, in _fit_stage\n",
      "    check_input=False, X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 1142, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 366, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "KeyboardInterrupt\n",
      "Process Process-68:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-79-e192e81d905d>\", line 28, in train_and_pickle_model\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1465, in fit\n",
      "    begin_at_stage, monitor, X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1529, in _fit_stages\n",
      "    X_csc, X_csr)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1194, in _fit_stage\n",
      "    check_input=False, X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 1142, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 366, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "KeyboardInterrupt\n",
      "Process Process-69:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-79-e192e81d905d>\", line 28, in train_and_pickle_model\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1465, in fit\n",
      "    begin_at_stage, monitor, X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1529, in _fit_stages\n",
      "    X_csc, X_csr)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1194, in _fit_stage\n",
      "    check_input=False, X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 1142, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/u1b1700/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 366, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "proc_queue = multiprocessing.Queue()\n",
    "label_list = list(label_cols.copy())\n",
    "\n",
    "# # initialize lists for models and mean scores\n",
    "model_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "accuracy_list = []\n",
    "feat_df_list = []\n",
    "\n",
    "# initialize dataframe to write out feature importances\n",
    "outfile = pd.DataFrame()\n",
    "\n",
    "X = cust_grp.loc[:, model_cols]\n",
    "\n",
    "while len(label_list) > 0:\n",
    "    sublist = []\n",
    "    for lab in label_list[:4]:\n",
    "        sublist.append(lab)\n",
    "        label_list.remove(lab)\n",
    "        \n",
    "    print(sublist)\n",
    "    \n",
    "    jobs = []\n",
    "    for label_col in sublist:\n",
    "        y = cust_grp.loc[:, label_col]\n",
    "        \n",
    "        jobs.append(multiprocessing.Process(target=train_and_pickle_model, \n",
    "                                            args=(cust_grp, X, y, label_col, \n",
    "                                                  proc_queue)))\n",
    "                    \n",
    "    for job in jobs:\n",
    "        job.start()\n",
    "        \n",
    "    for job in jobs:\n",
    "        job.join()\n",
    "        f1_list.append(proc_queue.get())\n",
    "#         recall_list.append(proc_queue.get())\n",
    "#         precision_list.append(proc_queue.get())\n",
    "#         accuracy_list.append(proc_queue.get())\n",
    "#         feat_df_list.append(proc_queue.get())\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Mean Scores:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'ListProxy' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-433a7ba01501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print mean scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------\\nMean Scores:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tF1 Score: {np.mean(f1_list)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tRecall Score: {np.mean(recall_list)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tPrecision Score: {np.mean(precision_list)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3118\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/cohorts_venv/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'ListProxy' and 'int'"
     ]
    }
   ],
   "source": [
    "# print mean scores\n",
    "print('-----------\\nMean Scores:')\n",
    "print(f'\\tF1 Score: {np.mean(f1_list)}')\n",
    "print(f'\\tRecall Score: {np.mean(recall_list)}')\n",
    "print(f'\\tPrecision Score: {np.mean(precision_list)}')\n",
    "print(f'\\tAccuracy Score: {np.mean(accuracy_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # write out files for feature importance and f1 scores\n",
    "# outfile.to_csv(f'../data/feat_imp_{partial_pkl_name}.csv', index=False)\n",
    "\n",
    "# f1_df = pd.DataFrame({'pkl_name': model_list, 'f1_score': f1_list})\n",
    "# f1_df.to_csv(f'../data/f1_scores_{partial_pkl_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
